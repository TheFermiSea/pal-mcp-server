{
  "_README": {
    "description": "Model metadata for vibeproxy endpoint at http://localhost:8317/v1",
    "providers": {
      "anthropic": "Direct Anthropic API",
      "antigravity": "Antigravity proxy (Gemini Flash, Gemini 3, hybrid models)",
      "github-copilot": "GitHub Copilot (Claude, GPT-5, Grok)",
      "google": "Native Google Gemini",
      "openai": "Direct OpenAI API"
    }
  },
  "models": [
    {
      "model_name": "gemini-2.5-flash",
      "aliases": ["ag-flash", "flash"],
      "context_window": 1000000,
      "max_output_tokens": 65536,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Gemini 2.5 Flash via Antigravity",
      "intelligence_score": 14
    },
    {
      "model_name": "gemini-2.5-flash-lite",
      "aliases": ["ag-flash-lite", "flash-lite"],
      "context_window": 1000000,
      "max_output_tokens": 65536,
      "supports_extended_thinking": false,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Gemini 2.5 Flash Lite via Antigravity",
      "intelligence_score": 12
    },
    {
      "model_name": "gemini-2.5-pro",
      "aliases": ["g-pro", "gemini-pro"],
      "context_window": 2000000,
      "max_output_tokens": 65536,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Gemini 2.5 Pro via Google (native)",
      "intelligence_score": 18
    },
    {
      "model_name": "gemini-3-flash-preview",
      "aliases": ["ag-g3-flash", "g3-flash"],
      "context_window": 1000000,
      "max_output_tokens": 65536,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Gemini 3 Flash Preview via Antigravity",
      "intelligence_score": 16
    },
    {
      "model_name": "gemini-3-pro-preview",
      "aliases": ["ag-g3-pro", "g3-pro"],
      "context_window": 2000000,
      "max_output_tokens": 65536,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Gemini 3 Pro Preview via Antigravity",
      "intelligence_score": 19
    },
    {
      "model_name": "gemini-claude-sonnet-4-5-thinking",
      "aliases": ["ag-sonnet-think"],
      "context_window": 200000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Claude Sonnet 4.5 with thinking via Antigravity",
      "intelligence_score": 18
    },
    {
      "model_name": "gemini-claude-opus-4-5-thinking",
      "aliases": ["ag-opus-think"],
      "context_window": 200000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Claude Opus 4.5 with thinking via Antigravity",
      "intelligence_score": 20
    },
    {
      "model_name": "claude-opus-4-5-20251101",
      "aliases": ["anthropic-opus", "a-opus"],
      "context_window": 200000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Claude Opus 4.5 via Anthropic (direct)",
      "intelligence_score": 20
    },
    {
      "model_name": "claude-sonnet-4-5-20250929",
      "aliases": ["anthropic-sonnet", "a-sonnet"],
      "context_window": 200000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Claude Sonnet 4.5 via Anthropic (direct)",
      "intelligence_score": 17
    },
    {
      "model_name": "claude-sonnet-4.5",
      "aliases": ["gh-sonnet", "copilot-sonnet"],
      "context_window": 200000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Claude Sonnet 4.5 via GitHub Copilot",
      "intelligence_score": 17
    },
    {
      "model_name": "claude-opus-4.5",
      "aliases": ["gh-opus", "copilot-opus"],
      "context_window": 200000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Claude Opus 4.5 via GitHub Copilot",
      "intelligence_score": 20
    },
    {
      "model_name": "claude-haiku-4.5",
      "aliases": ["gh-haiku", "copilot-haiku"],
      "context_window": 200000,
      "max_output_tokens": 64000,
      "supports_extended_thinking": false,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "Claude Haiku 4.5 via GitHub Copilot",
      "intelligence_score": 12
    },
    {
      "model_name": "gpt-5.2-codex",
      "aliases": ["gh-codex", "copilot-codex"],
      "context_window": 400000,
      "max_output_tokens": 128000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "GPT 5.2 Codex via GitHub Copilot",
      "intelligence_score": 18
    },
    {
      "model_name": "gpt-5.2",
      "aliases": ["gh-gpt5", "copilot-gpt5"],
      "context_window": 400000,
      "max_output_tokens": 128000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": true,
      "description": "GPT 5.2 via GitHub Copilot",
      "intelligence_score": 16
    },
    {
      "model_name": "gpt-5-codex-mini",
      "aliases": ["openai-codex-mini"],
      "context_window": 400000,
      "max_output_tokens": 128000,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "supports_images": false,
      "description": "GPT 5 Codex Mini via OpenAI (direct)",
      "intelligence_score": 14
    }
  ]
}
